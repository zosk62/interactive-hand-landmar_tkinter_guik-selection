{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57e4abb-445e-474e-92c8-d23222c6cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sarak\\anaconda3\\envs\\portf01\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[0, 189, 379]\n",
      "[0, 172, 347]\n",
      "[0, 170, 329]\n",
      "[0, 175, 312]\n",
      "[0, 184, 278]\n",
      "[0, 192, 271]\n",
      "[0, 201, 269]\n",
      "[0, 191, 265]\n",
      "[0, 192, 249]\n",
      "[0, 190, 230]\n",
      "[0, 175, 232]\n",
      "[0, 142, 221]\n",
      "[0, 135, 222]\n",
      "[0, 132, 225]\n",
      "[0, 125, 224]\n",
      "[0, 121, 221]\n",
      "[0, 119, 220]\n",
      "[0, 119, 223]\n",
      "[0, 109, 231]\n",
      "[0, 109, 232]\n",
      "[0, 109, 234]\n",
      "[0, 106, 236]\n",
      "[0, 93, 244]\n",
      "[0, 89, 248]\n",
      "[0, 88, 246]\n",
      "[0, 81, 246]\n",
      "[0, 72, 247]\n",
      "[0, 69, 247]\n",
      "[0, 71, 247]\n",
      "[0, 71, 243]\n",
      "[0, 69, 244]\n",
      "[0, 68, 242]\n",
      "[0, 64, 242]\n",
      "[0, 65, 242]\n",
      "[0, 52, 240]\n",
      "[0, 54, 236]\n",
      "[0, 54, 238]\n",
      "[0, 46, 237]\n",
      "[0, 43, 236]\n",
      "[0, 47, 234]\n",
      "[0, 42, 234]\n",
      "[0, 78, 216]\n",
      "[0, 36, 252]\n",
      "[0, 81, 229]\n",
      "[0, 38, 276]\n",
      "[0, 35, 295]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "\n",
    "class handDetector():\n",
    "    def __init__(self, mode=False, maxHands=2, model_complexity=1, detectionCon=0.5, trackCon=0.5):\n",
    "    # def __init__(self):\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.model_complexity = model_complexity\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        \n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.model_complexity, self.detectionCon, self.trackCon)\n",
    "        # self.hands = self.mpHands.Hands()\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "    def findHands(self, img, draw=True): \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB) \n",
    "        \n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def findPosition(self, img, handNo=0, draw =True):\n",
    "        lmList = []  \n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                # print(id, lm)\n",
    "                h, w, c = img.shape # (height, width, channels)\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                # print(\"id, cx, cy:\", id, cx, cy)\n",
    "                lmList.append([id, cx, cy])  \n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 10, (255, 0, 255), cv2.FILLED)\n",
    "        return lmList\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "def main():\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    detector = handDetector()\n",
    "    \n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img1 = detector.findHands(img)\n",
    "        lmList = detector.findPosition(img1)\n",
    "        if len(lmList) != 0:\n",
    "            print(lmList[0])\n",
    "\n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps= 1/(cTime-pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(img1, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
    "        cv2.imshow(\"Image\", img1)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969098d-e647-404a-9859-b70d53d2653c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portf01_kernel",
   "language": "python",
   "name": "portf01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
